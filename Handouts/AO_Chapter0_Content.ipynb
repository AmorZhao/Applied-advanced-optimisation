{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ank_7OLLfPs1"
      },
      "source": [
        "# ELEC70066 - Applied Advanced Optimisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObYU0Y4wkvuT"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "**Author:** Dr Giordano Scarciotti (g.scarciotti@imperial.ac.uk) - Imperial College London\n",
        "\n",
        "**Module:** ELEC70066 - Applied Advanced Optimisation\n",
        "\n",
        "**Version:** 1.1.0 - 10/01/2025\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGQIz0_BlA7r"
      },
      "source": [
        "## Aim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGxbCB8dfWrc"
      },
      "source": [
        "The aim of this module is to equip you with the tools to formulate and solve applied optimisation problems. The module covers several topics in optimisation such as convex optimisation, integer programming, multi-objective optimisation and formulation and solution of applied optimisation problems. Most of these topics are covered through the lens of convex optimisation. Each topic is covered with an application-driven mindset (i.e. techniques are covered because they are useful in practice).\n",
        "\n",
        "The module assumes prior basic optimisation knowledge such as descent methods and constrained optimisation. This prior knowledge may be acquired in the Autumn module \"Optimisation\" although that module is not a prerequisite. Basic knowledge of Python is assumed (equivalent to any 4/5-hour long tutorial course available online for free).\n",
        "\n",
        "A basic Python tutorial will take place on the 16th of January at 2pm in 508B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywz987HkRSG-"
      },
      "source": [
        "The induction presentation of Friday 10/01/2025 will be available on Panoto [at this link](https://imperial.cloud.panopto.eu/Panopto/Pages/Sessions/List.aspx#folderID=%220987b949-8618-4083-8099-b1db014cc7c2%22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cPCgJc0ba_0"
      },
      "source": [
        "## Delivery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVv9_3yZfWtz"
      },
      "source": [
        "The module is delivered using Flipped Classroom with Team-Based Learning. During the first meeting I will explain in detail the teaching delivery of the course. In short, the lectures are recorded and provided to you in advance, while study activities will be done together in groups during the Friday meetings. Moreover, the module will make use of \"smart handouts\". These are Python notebooks in which videos, text, code and exercises are all blended together.\n",
        "\n",
        "Every week you will:\n",
        "\n",
        "- Watch the recorded lectures and read the handouts at home.\n",
        "- At any time during the week, you will complete a short test (iRAT) at home. This is an easy test: its purpose is just ensure that you watched the videos and read the handouts as expected.\n",
        "- In class you will be divided in groups and work on problems together for the first hour and a half. In the last half an hour, your group will solve a small assessed exercise as a team (tRAT)\n",
        "\n",
        "Note that this course has both a strong theoretical component and a strong applied component:\n",
        "\n",
        "- In class, you will be asked every week to solve an applied optimisation problem, from the formulation to the numerical solution. There will be also theoretical exercises.\n",
        "- At home, you will cover the theory in the lectures.\n",
        "\n",
        "The coursework will mostly focus on your applied skills. The exam will mostly focus on your theoretical skills."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W-bHxWRfWv_"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQttbFvQi0ZL"
      },
      "source": [
        "The module for the academic year 2024/2025 will cover the following chapters:\n",
        "\n",
        "*   **Chapter 1:** [Approximation and Fitting Problems](https://colab.research.google.com/drive/1efBkJ5F5U6QpIT4nU6QzxM5mZq5I6iv4?usp=sharing) (*Applications*)\n",
        "*   **Chapter 2:** Statistical Problems (*Applications*)\n",
        "*   **Chapter 3:** Convex Sets (*Theory - Mathematics*)\n",
        "*   **Chapter 4:** Convex Functions (*Theory - Mathematics*)\n",
        "*   **Chapter 5:** Convex Optimisation Problems (*Theory - Mathematics*)\n",
        "*   **Chapter 6:** Duality (*Theory - Mathematics*)\n",
        "*   **Chapter 7:** Unconstrained Minimisation (*Algorithms*)\n",
        "*   **Chapter 8:** Equality Constraints Minimisation (*Algorithms*)\n",
        "*   **Chapter 9:** Interior-points Methods\n",
        "*   **Chapter 10:** TBC\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oQx7BxY0ebq"
      },
      "source": [
        "## Basic definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9Bw1QZ30jwh"
      },
      "source": [
        "The material of this chapter is adapted from the book *Boyd & Vandenberghe \"Convex Optimization\"* which from now on we refer to as $[1]$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf8YMNCl0mfP"
      },
      "source": [
        "An optimisation problem consists in finding an\n",
        "\n",
        "$$\n",
        "x=(x_1,\\dots,x_n)\n",
        "$$\n",
        "\n",
        "that minimizes a function $f_0$ among all $x$ that satisfy the conditions\n",
        "\n",
        "$$\n",
        "f_i(x) \\le 0\n",
        "$$\n",
        "\n",
        "for all $i = 1,\\dots,m$ and\n",
        "\n",
        "$$\n",
        "h_i(x) = 0\n",
        "$$\n",
        "\n",
        "for all $i = 1,\\dots,p$. This problem is compactely written as\n",
        "\n",
        "$$\n",
        "\\begin{array}{lll}\n",
        "\\min & f_0(x) &\\\\\n",
        "s.t. & f_i(x) \\le 0, & i = 1,\\dots,m\\\\\n",
        "& h_i(x)=0,  & i = 1,\\dots,p.\n",
        "\\end{array} \\tag{1}\n",
        "$$\n",
        "\n",
        "We call $x \\in \\mathbb{R}^n$ the *optimisation variable* and the function $f_0 : \\mathbb{R}^n \\to \\mathbb{R}$ the *objective function* or *cost function*. The inequalities $f_i(x) \\le 0$ are called *inequality constraints*, and the\n",
        "corresponding functions $f_i : \\mathbb{R}^n \\to \\mathbb{R}$ are called the *inequality constraint functions*. The equations $h_i(x) = 0$ are called the *equality constraints*, and the functions $h_i : \\mathbb{R}^n \\to \\mathbb{R}$ are the *equality constraint functions*. If there are no constraints (i.e.,\n",
        "$m = p = 0$) we say problem $(1)$ is *unconstrained*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-oBD55Z0pgq"
      },
      "source": [
        "We say a feasible point $x$ is *locally optimal* if there is an $R > 0$ such that $x$ solves the optimisation problem\n",
        "\n",
        "$$\n",
        "\\begin{array}{lll}\n",
        "\\displaystyle \\min_z & f_0(z) &\\\\\n",
        "s.t. & f_i(z) \\le 0, & i = 1,\\dots,m\\\\\n",
        "& h_i(z)=0,  & i = 1,\\dots,p\\\\\n",
        "& ||z-x||_2 \\le R\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "Roughly speaking, this means that $x$ minimizes $f_0$ over nearby points\n",
        "in the feasible set. The term \"globally optimal\" is sometimes used for \"optimal\"\n",
        "to distinguish between \"locally optimal\" and \"optimal\". If $x$ is feasible and $f_i(x) = 0$, we say the $i$-th inequality constraint $f_i(x) \\le 0$ is *active* at $x$. If $f_i(x) < 0$, we say the constraint $f_i(x) \\le 0$ is *inactive*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4bGDbfE0riD"
      },
      "source": [
        "---\n",
        "\n",
        "**Example 0.1:**\n",
        "*    $f_0(x) = \\frac{1}{x}$ over $\\textbf{dom }f_0 = \\mathbb{R}_{++}$: $p^* = 0$, but the optimal value is not achieved.\n",
        "*    $f_0(x) = −\\log x$ over $\\textbf{dom }f_0 = \\mathbb{R}_{++}$: $p^* = -\\infty$, so this problem is unbounded below.\n",
        "*    $f_0(x) = x \\log x$ over $\\textbf{dom }f_0 = \\mathbb{R}_{++}$: $p^* = −\\frac{1}{e}$, achieved at the optimal point $x^* = \\frac{1}{e}$.\n",
        "*    $f_0(x) = x^3-3x$: $p^* = −\\infty$, local optimum at $x = 1$.\n",
        "\n",
        "---\n",
        "\n",
        "**dom** here: domain (the domain of the opti problem). \n",
        "\n",
        "$p^*$: optimal value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Feasibility problem**\n",
        "\n",
        "$$\n",
        "\\begin{array}{lll}\n",
        "find & x \\\\\n",
        "s.t. & f_i(z) \\le 0, & i = 1,\\dots,m\\\\\n",
        "& h_i(z)=0,  & i = 1,\\dots,p\n",
        "\\end{array}\n",
        "$$"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
